{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core import debugger as idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 缓存图片，加速训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "应在split之后再执行cache. 因为，若在split之前的ItemList执行cache，则在下一步split时，会新建train和valid这两个ItemList，而新建的ItemList是不带有cached_images属性的，那么你在split之前执行的cache就不起作用了。  \n",
    "理论上说，你可以在split之后的任何一处执行cache，例如对ItemLists的train和valid这两个ItemList分别执行cache_image，但是我们建议在databunch之后再执行cache_image，而且为了方便此操作而定义了Databunch.cache_ds_image()方法。  \n",
    "这样建议的原因是：  \n",
    "- 在逻辑上更合理。缓存图片的目的是加速训练过程中的图片加载速度，而为模型提供训练数据的是databunch，那么在databunch处执行缓存就在流程上更加清晰。\n",
    "- 在资源占用上更合理。一旦我们执行了缓存图片，那么就占用了大量的内存，后续的程序执行中可用内存就更少了。所以我们不应该提早的把这个内存占用起来，而应该在最后时刻再占用，这个时刻就是训练即将开始时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# 为ImageList类添加cache_image方法\n",
    "def cache_image(self):\n",
    "    cached_images = [self.open(fn) for fn in self.items]\n",
    "    self.cached_images = cached_images\n",
    "\n",
    "ImageList.cache_image = cache_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# 修改ImageList类的get方法\n",
    "def get(self,i):\n",
    "    if hasattr(self, 'cached_images'):\n",
    "        res = self.cached_images[i]\n",
    "    else:\n",
    "        fn = super(ImageList, self).get(i)\n",
    "        res = self.open(fn)\n",
    "        \n",
    "    self.sizes[i] = res.size\n",
    "    return res\n",
    "\n",
    "ImageList.get = get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "# 为 Databunch类添加cache_ds_img方法\n",
    "def cache_ds_img(self):\n",
    "    self.train_ds.x.cache_image()\n",
    "    self.valid_ds.x.cache_image()\n",
    "    \n",
    "ImageDataBunch.cache_ds_img = cache_ds_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## get_label_from_df 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "pat_coord = re.compile(r'\\d+')\n",
    "pat_clas = re.compile(r'\\w+')\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.png)$')\n",
    "kkk = 0\n",
    "def get_label_from_df(fn, df, pat_imgName, box_col, cat_col):\n",
    "    '''\n",
    "    fn: \n",
    "        file path.\n",
    "    df: \n",
    "        a dataframe stores all the label information, imageName shoud be as index.\n",
    "    repat_imgName: \n",
    "        a regular expression pattern, used to find the imageName from fn, where imageName is stored in df \n",
    "    box_col:\n",
    "        the column name of bounding boxs\n",
    "    cat_col:\n",
    "        the column name of categories\n",
    "    '''\n",
    "    pat_num = re.compile(r'\\d+')\n",
    "    pat_cat = re.compile(r'\\w+')\n",
    "    \n",
    "    fn = pat_imgName.findall(fn)[0]\n",
    "    \n",
    "    boxes = df.loc[fn,box_col]\n",
    "    boxes = pat_num.findall(boxes)\n",
    "    boxes = list(map(np.long, boxes))\n",
    "    boxes = np.array(boxes).reshape(-1,4)\n",
    "    boxes = boxes.tolist()\n",
    "    \n",
    "    cats = df.loc[fn,cat_col]\n",
    "    cats = pat_clas.findall(cats)\n",
    "    \n",
    "    assert len(boxes)==len(cats), 'length of bounding boxes and categories not equeal.'\n",
    "        \n",
    "    return (boxes,cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 修改 ImageBBox.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "使可以表示“无目标”。  \n",
    "在目标检测任务中，训练集中可以有无目标的训练样本，其价值在于告诉模型这些是“我们不需要的”。但是在fastai的目标检测中是不支持无目标的训练样本的。  \n",
    "为了增加对“无目标”样本的支持，需要考虑怎样表示“无目标”的标注信息。fastai中以ImageBBox来表示目标检测任务中的标注信息，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@classmethod\n",
    "def create(cls, h:int, w:int, bboxes:Collection[Collection[int]], labels:Collection=None, classes:dict=None,\n",
    "           pad_idx:int=0, scale:bool=True)->'ImageBBox':\n",
    "    \"Create an ImageBBox object from `bboxes`.\"\n",
    "    # the following 3 lines are added by xutongye\n",
    "#     assert isinstance(bboxes,list) and isinstance(labels,list), 'bboxes and labels should be of type list.'\n",
    "    if isinstance(bboxes,list) and len(bboxes)==0:\n",
    "        bboxes = [[0,0,0,0]]\n",
    "    # the code in fastai\n",
    "    if isinstance(bboxes, np.ndarray) and bboxes.dtype == np.object: bboxes = np.array([bb for bb in bboxes])\n",
    "    bboxes = tensor(bboxes).float()\n",
    "    tr_corners = torch.cat([bboxes[:,0][:,None], bboxes[:,3][:,None]], 1)\n",
    "    bl_corners = bboxes[:,1:3].flip(1)\n",
    "    bboxes = torch.cat([bboxes[:,:2], tr_corners, bl_corners, bboxes[:,2:]], 1)\n",
    "    flow = FlowField((h,w), bboxes.view(-1,2))\n",
    "    return cls(flow, labels=labels, classes=classes, pad_idx=pad_idx, y_first=True, scale=scale)\n",
    "\n",
    "ImageBBox.create = create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 修改 ImageBBox._compute_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _compute_boxes(self) -> Tuple[LongTensor, LongTensor]:\n",
    "    '''\n",
    "    Check if there are bad bboxes (boxes whose area is zero). If there are, delete them.\n",
    "    Bad boxes may be due to transformations, for example may rotate a bbox out of the image.\n",
    "    Bad boxes may be added in the initial, because there indeed no object, but you has to add one, or there will be confilicts occur if you dont. \n",
    "    '''\n",
    "    bboxes = self.flow.flow.flip(1).view(-1, 4, 2).contiguous().clamp(min=-1, max=1)\n",
    "    mins, maxes = bboxes.min(dim=1)[0], bboxes.max(dim=1)[0]\n",
    "    bboxes = torch.cat([mins, maxes], 1)\n",
    "    mask = (bboxes[:,2]-bboxes[:,0] > 0) * (bboxes[:,3]-bboxes[:,1] > 0)\n",
    "    #if len(mask) == 0: return tensor([self.pad_idx] * 4), tensor([self.pad_idx])\n",
    "    # 上句判断 len(mask)==0 是个bug\n",
    "    if mask.sum()==0: \n",
    "        return tensor([[self.pad_idx]*4]), tensor([self.pad_idx])\n",
    "    res = bboxes[mask]\n",
    "    if self.labels is None: return res,None\n",
    "    return res, self.labels[to_np(mask).astype(bool)]\n",
    "\n",
    "ImageBBox._compute_boxes = _compute_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 增加transform操作：rot90_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(该函数引用自kechan的[分享](https://github.com/kechan/FastaiPlayground))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "注意：在fastai中，flip_lr 和 dihedral 有 tfmpixel 和 tfmaffine（flip_affine,dihedral_affine)两种实现方式。\n",
    "- tfmpixel方式是直接对图像数据（tensor）的维度做操作；\n",
    "- tfmaffine则是通过(i)create coordinate grid; (ii)affine matrix multiplicatioin; (iii)interpolation的方式来实现（见[该说明](https://forums.fast.ai/t/new-coordinate-transforms-pipeline/19790)）。   \n",
    "\n",
    "对于flip_lr和dihedral两种操作来说，tfmpixel实现方式的计算量更小，但是它仅能对Image做操作，而不能用于ImagePoints和ImageBBox. tfmaffine则更具有通用性.  \n",
    "\n",
    "此处实现的 rot90 操作也可以 tfmpixel 和 tfmaffine 来实现，而因为我们这里要对 Image 和 ImageBBox 都做该操作，所以我们以 tfmaffine 的方式实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def _rot90_affine(k:partial(uniform_int, 0, 3)):\n",
    "    \"Randomly rotate `x` image based on `k` as in np.rot90\"\n",
    "    if k%2 == 0:\n",
    "        x = -1. if k&2 else 1.\n",
    "        y = -1. if k&2 else 1.\n",
    "        \n",
    "        return [[x, 0, 0.],\n",
    "                [0, y, 0],\n",
    "                [0, 0, 1.]]\n",
    "    else:\n",
    "        x = 1. if k&2 else -1.\n",
    "        y = -1. if k&2 else 1.\n",
    "        \n",
    "        return [[0, x, 0.],\n",
    "                [y, 0, 0],\n",
    "                [0, 0, 1.]]\n",
    "\n",
    "rot90_affine = TfmAffine(_rot90_affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## get_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_stats(data,dl_types=[DatasetType.Train]):\n",
    "    '''\n",
    "    根据一个databunch中的所有指定的（图片）数据来统计各通道的均值和标准差。\n",
    "    --------------------------------\n",
    "    参数：\n",
    "    -- data：一个DataBunch对象\n",
    "    -- dl_types：一个list，其元素可选自DatasetType.Train, DatasetType.Valid, DatasetType.Test\n",
    "    --------------------------------\n",
    "    返回值：\n",
    "    -- mean：图片三个通道上的均值\n",
    "    -- std：图片三个通道上的标准差\n",
    "    '''\n",
    "    tn,sm,ssm = 0,torch.zeros(3,device=data.device),torch.zeros(3,device=data.device) # tn: total number; sm: sum; ssm: square sum\n",
    "    for dl_type in dl_types:\n",
    "        dl = data.dl(dl_type)\n",
    "        for x,_ in dl:\n",
    "            tn += x.shape[0]\n",
    "            sm += x.mean((0,2,3))*x.shape[0]\n",
    "            ssm += x.pow(2).mean((0,2,3))*x.shape[0]\n",
    "            \n",
    "    mean = sm/tn\n",
    "    std = (ssm/tn - mean.pow(2)).sqrt()\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## train和valid数据统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def databunch_statistics(data:DataBunch,show=True):\n",
    "    train_ys = data.train_ds.y\n",
    "    valid_ys = data.valid_ds.y\n",
    "    \n",
    "    hw_statistics = [[],[]]\n",
    "    cat_statistics = [dict([(cla,0) for cla in data.train_dl.y.classes[1:]]),\n",
    "                      dict([(cla,0) for cla in data.train_dl.y.classes[1:]])]\n",
    "    \n",
    "    for hw_stat,cat_stat,ys in zip(hw_statistics, cat_statistics, [train_ys,valid_ys]):\n",
    "        for y in ys:\n",
    "            if len(y.labels)==0: continue\n",
    "\n",
    "            # 统计目标类别\n",
    "            for clas in y.labels:\n",
    "                cat_stat[clas.obj] += 1\n",
    "\n",
    "            # 统计高宽\n",
    "            pts = y.flow.flow\n",
    "            pts = pts.reshape(-1,4,2)\n",
    "            hws = pts.max(dim=1)[0] - pts.min(dim=1)[0]\n",
    "            hw_stat += [hws]\n",
    "            \n",
    "    train_cat,valid_cat = cat_statistics\n",
    "    train_hw,valid_hw = hw_statistics\n",
    "    train_hw = torch.cat(train_hw,dim=0)\n",
    "    valid_hw = torch.cat(valid_hw,dim=0)\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        \n",
    "        # 显示各类别计数\n",
    "        print('{:>41}{:>10}'.format('train','valid'))\n",
    "        print('------------------------------------------------------')\n",
    "        train_tot = 0\n",
    "        valid_tot = 0\n",
    "        for k,v in train_cat.items():\n",
    "            valid_v = valid_cat[k]\n",
    "            print('{:>30}:{:>10}{:>10}'.format(k,v,valid_v))\n",
    "            train_tot += v\n",
    "            valid_tot += valid_v\n",
    "        print('------------------------------------------------------')\n",
    "        print('{:>30}:{:>10}{:>10}'.format('total',train_tot,valid_tot))\n",
    "        \n",
    "        # 绘制高宽分布\n",
    "        print('\\n\\n')\n",
    "        print('red for train; blue for valid:')\n",
    "        plt.scatter(train_hw[:,0],train_hw[:,1],c='r',marker='.',linewidths=2);\n",
    "        plt.scatter(valid_hw[:,0],valid_hw[:,1],c='b',marker='.',linewidths=0);\n",
    "\n",
    "    \n",
    "    return train_hw, valid_hw, train_cat, valid_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做些设置\n",
    "# data_root = './data/tiny_ds_20200331/'\n",
    "data_root = './data/ds_20200227/'\n",
    "data_root = Path(data_root)\n",
    "\n",
    "csv_name = 'gends.csv'\n",
    "csv_path = data_root/csv_name\n",
    "\n",
    "img_subpath = 'images'\n",
    "img_path = data_root/img_subpath\n",
    "\n",
    "bs = 64\n",
    "\n",
    "device = 'cpu'\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入csv，稍作处理，方便get_label函数操作\n",
    "df = pd.read_csv(csv_path,index_col=0)\n",
    "df = df.set_index('image')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ItemList\n",
    "data = ObjectItemList.from_csv(path=data_root, csv_name=csv_name, cols='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ItemList to get ItemLists\n",
    "data = data.split_by_rand_pct(valid_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# label ItemLists to get LabelLists\n",
    "pat_imgName = re.compile(r'(\\w+/\\d+\\.jpg)$')\n",
    "func = partial(get_label_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "data = data.label_from_func(func=func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add transforms\n",
    "trn_tfms = [*zoom_crop(scale=(0.9,1.1),do_rand=True,p=1),\n",
    "            rot90_affine(use_on_y=True)]\n",
    "val_tfms = []\n",
    "\n",
    "data = data.transform(tfms=[trn_tfms,val_tfms], tfm_y=True, remove_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于 *add transforms***  \n",
    "  \n",
    "**1，添加哪些transform？**  \n",
    "- 缩放：同一类符号是否会出现缩放上的不同？这还需要对数据做统计观察。\n",
    "- 90,180,270度旋转：我们观察到了同一类符号会有这类旋转。  \n",
    "\n",
    "**2，为什么zoom_crop前加 \\* 符号？**  \n",
    "LabelLists.transform的参数tfms必须满足形式[[Tfm,Tfm,...],[Tfm,Tfm,...]]，（其中Tfm表示一个Transform对象）。而zoom_crop返回的是一个list：[Tfm,Tfm]，通过前加\\*对list解包。\n",
    "  \n",
    "**3，关于transform的remove_out参数：**  \n",
    "从fastai的源码看，remove_out起作用在image.py->ImagePoints.data函数中调用_remove_points_out 函数：只要有超过[-1,1]的点，它就把它删掉。但调试发现，不论remove_out为True或False，都没有调用到_remove_points_out，所以没有搞清楚remove_out到底如何能起作用。试验发现，不论remove_out为True或False，其现象都一样，经过transform（例如放大）后：\n",
    "- 若bbox的包围区域整个落在了边界之外，则它被删除；\n",
    "- 只要bbox的包围区域有部分落在边界之内，则它被保留，但会被切割在[-1,1]范围内。\n",
    "\n",
    "**4，ds_tfms 和 dl_tfms**  \n",
    "ds_tfms指添加在dataset上的transform，dl_tfms指添加在deviceDataloader（fastai的类）上的transform. dl_tfms的优点是可以在GPU上按batch做处理，大大提高效率。但是目前就我从fastai-v1的源码来看，其对dl_tfms的支持还相对较少，基本需要完全自己编写dl_tfms函数。从时间上考虑，我们暂时选择都用 ds_tfms，后续可以改为使用 dl_tfms，或者 fastai-v2 对 dl_tfms 有更完善的支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create DataBunch from LabelLists\n",
    "data = data.databunch(bs=bs, device=device, collate_fn=bb_pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "# 当bs较大时，可以不必传入stats参数，这是normalize函数内部会取data的一个batch来统计stats，并以此近似整个数据集的stats\n",
    "# 但是当bs较小时，这样做就很不准确，需要先统计整个数据集的stats，在这里作为参数传入\n",
    "data = data.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缓存图片\n",
    "# data.cache_ds_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl = data.train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdldl = tdl.dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdldl.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看统计信息\n",
    "databunch_statistics(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zip process as a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将process组中的过程打包为函数，方便其它模块快速获取结果的函数。该组下的函数一般都是为了测试用，而非通用。因为在设计这些函数时，更多的考虑是调用简单，而不会仔细考虑其灵活性和合理性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# 这个函数是为了在其它模块的设计时快速构造databunch\n",
    "def get_databunch(data_root='./data/ds_20200227', csv_name='gends.csv', valid_pct=0.2, bs=64, device=torch.device('cpu'), cache=False):\n",
    "    '''\n",
    "    --------------------------------\n",
    "    参数：\n",
    "    -- data_root：数据集的总目录\n",
    "    -- csv_name：存放标注信息的csv文件名，其要符合“对csv的要求”\n",
    "    -- valid_pct：随机分割训练/验证集，该参数指定验证集的比例\n",
    "    -- bs：batch size\n",
    "    -- device：在datalaoder迭代时，dataloader先将batch加载到该device，做batch transform，然后返回。\n",
    "    -- cache：dataset是否将所有图片预缓存入内存\n",
    "    --------------------------------\n",
    "    返回值：\n",
    "    -- 一个databunch对象\n",
    "    --------------------------------\n",
    "    对csv的要求：\n",
    "    1，带index\n",
    "    2，存放图片名的列名称为\"image\"\n",
    "    3，存放bbox信息的列名称为\"box\"\n",
    "    4，存放类别信息的列名称为\"cls\"\n",
    "    --------------------------------\n",
    "    '''\n",
    "    data_root = Path(data_root)\n",
    "    csv_name = Path('gends.csv')\n",
    "    # 读入csv，稍作处理，方便get_label函数操作\n",
    "    csv_path = data_root/csv_name\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    df = df.set_index('image')\n",
    "\n",
    "    # ItemList\n",
    "    data = ObjectItemList.from_csv(path=data_root, csv_name=csv_name, cols='image')\n",
    "\n",
    "    # split ItemList to get ItemLists\n",
    "    data = data.split_by_rand_pct(valid_pct=valid_pct)\n",
    "\n",
    "    # label ItemLists to get LabelLists\n",
    "    pat_imgName = re.compile(r'(\\w+/\\d+\\.jpg)$')\n",
    "    func = partial(get_label_from_df, df=df, pat_imgName=pat_imgName, box_col='box', cat_col='cls')\n",
    "    data = data.label_from_func(func=func)\n",
    "\n",
    "    # add transforms\n",
    "    trn_tfms = [*zoom_crop(scale=(0.9,1.1),do_rand=True,p=1),\n",
    "                rot90_affine(use_on_y=True)]\n",
    "    val_tfms = []\n",
    "\n",
    "    data = data.transform(tfms=[trn_tfms,val_tfms], tfm_y=True, remove_out=True)\n",
    "\n",
    "    # create DataBunch from LabelLists\n",
    "    data = data.databunch(bs=bs, device=device, collate_fn=bb_pad_collate, num_workers=0)\n",
    "\n",
    "    # normalize\n",
    "    data = data.normalize()\n",
    "    \n",
    "    # 缓存图片\n",
    "    if cache:\n",
    "        data.cache_ds_img()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted databunch.ipynb to ../exp/databunch.py\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../notebook2script.py --fname 'databunch.ipynb' --outputDir '../exp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
