{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basic_train import LearnerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.callbacks.general_sched import *\n",
    "from fastai.callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from IPython.core import debugger as idb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ..exp import nb_databunch\n",
    "from ..exp import nb_resnet_ssd\n",
    "from ..exp import nb_init_model\n",
    "from ..exp import nb_anchors_loss_metrics\n",
    "from ..exp import nb_optimizer\n",
    "from ..exp import nb_tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.basic_train import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os,shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomEpochLength(Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CustomEpochLength(Callback):\n",
    "    def __init__(self, epoch_len=1e99):\n",
    "        '''\n",
    "        在fastai定义的训练过程中，只有在一个epoch结束后才会进行一次valid loss和metrics计算。\n",
    "        在数据集很大，batch size很小时，一个epoch包含的iteration数非常多，就会导致非常多的iteration后才会进行一次valid loss和metrics\n",
    "        计算。这会是个问题，因为你往往根据valid loss或metrics来做一些决定，例如early stop，如果valid loss和metrics更新周期太长，可能\n",
    "        会使你错过最好的时机。\n",
    "        本callback使你能指定一个epoch包含更少的iteration.\n",
    "        注意：如果你指定一个epoch包含更多的iteration，则实际上本callback是不起作用的。\n",
    "        注意：如果你使用该callback，你要确定你的dataloader的sample方式是随机的，否则可能会导致每个epoch都只看到固定的一部分训练\n",
    "        数据，而另一部分训练数据永远不会参与训练。\n",
    "        ------------------------------------------------------\n",
    "        参数：\n",
    "        -- epoch_len：指定一个epoch包含多少个iteration，默认为一个非常大的数（1e99），这保证如果你使用了该callback但没有指定epoch_len，\n",
    "        那么实际上该callback是不起作用的.\n",
    "        '''\n",
    "        self.epoch_len=epoch_len\n",
    "        print('ALLERT: You are using CumtomEpochLength, please make sure that your training dataloader is using random sampler, or this may cause problem.')\n",
    "        \n",
    "    def on_batch_end(self, num_batch, **kwargs):\n",
    "        if (num_batch+1)%self.epoch_len: return\n",
    "        return {'stop_epoch': True}\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiAnneal_Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiAnneal_Scheduler(LearnerCallback):\n",
    "    def __init__(self, \n",
    "                 learn,\n",
    "                 base_lr_sched,\n",
    "                 monitor='valid',\n",
    "                 worseN_thres=3,\n",
    "                 annealRate=5,\n",
    "                 duration_thres=5,\n",
    "                 annealIte=100,\n",
    "                 phaseMaxN=3,\n",
    "                 finetune_stop=0):\n",
    "        '''\n",
    "        将训练过程分为多个constant lr训练阶段，当一个训练阶段到达平台期后，以线性下降的方式将lr衰减一定倍率，然后进入\n",
    "        下一个constant lr训练阶段，如此重复，直至最后一个训练到达平台期后结束训练。其中第一个训练阶段的lr由base_lr_sched决定。\n",
    "        参数：\n",
    "            -- learn：Learner对象\n",
    "            -- base_lr_sched：一个对learn的lr做scheduling的对象，它应该是constant lr的方式。本类就是通过自适应地修改它来修改对learn的lr的scheduling方式。\n",
    "            -- monitor：根据哪个损失值来判定是否达到平台期，字符串，可选'valid'或'train_smooth'。不论你选各个变量，监测周期都是一个epoch.\n",
    "            -- worseN_thres：当有warseN_thres个epoch都没有出现更好的loss时，认为达到了平台\n",
    "            -- annealRate：loss到达平台后，将当前使用的lr衰减至1/annealRate\n",
    "            -- duration_thres：一个constant lr训练阶段至少持续duration_thres个epoch\n",
    "            -- annealIte：lr衰减至lr/annealRate经历的iteration数\n",
    "            -- phaseMaxN：至多phaseMaxN个训练阶段\n",
    "            -- finetune_stop：一个整数，在某个train phase刚开始，其lr稳定后，决定是否结束微调，变为全模型学习。若为0，则不起作用，即整个训练\n",
    "            过程维持开始的微调策略；若大于phaseMaxN，也不会起作用。\n",
    "        '''\n",
    "        super().__init__(learn)\n",
    "        self.scheduler = base_lr_sched\n",
    "        self.monitor = monitor\n",
    "        self.worseN_thres = worseN_thres\n",
    "        self.annealRate = annealRate\n",
    "        self.duration_thres = duration_thres\n",
    "        self.annealIte = annealIte\n",
    "        self.phaseMaxN = phaseMaxN\n",
    "        self.finetune_stop = finetune_stop\n",
    "        \n",
    "        \n",
    "        self.best_loss = None\n",
    "        self.worseN = 0\n",
    "        self.phaseDuration = 0\n",
    "        self.phaseN = 0\n",
    "        self.expectConstantLr = False\n",
    "        \n",
    "        \n",
    "    def _get_monitoring_loss(self,**kwargs):\n",
    "        if self.monitor=='valid': loss = kwargs['last_metrics'][0]\n",
    "        if self.monitor=='train_smooth': loss = kwargs['smooth_loss']\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def _finetune_stop(self,iteration,**kwargs):\n",
    "        if self.finetune_stop==self.phaseN:\n",
    "            if isinstance(self.scheduler.start,Iterable) and len(self.scheduler.start)>1:\n",
    "                self.scheduler.start[0] = self.scheduler.start[1]\n",
    "                self.scheduler.end[0] = self.scheduler.end[1]\n",
    "                print(f'at iteration {iteration}, stop finetune and begin to train entire model.')\n",
    "                \n",
    "    \n",
    "    def on_epoch_end(self, epoch, num_batch, **kwargs):\n",
    "        # 更新当前phase持续周期\n",
    "        self.phaseDuration += 1\n",
    "        \n",
    "        loss = self._get_monitoring_loss(**kwargs)\n",
    "        \n",
    "        # 首次epoch\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "            return\n",
    "        \n",
    "        # 更新best_loss, self.warseN\n",
    "        if loss<self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.worseN = 0\n",
    "        else:\n",
    "            self.worseN += 1\n",
    "        \n",
    "        # 若达到phase结束条件\n",
    "        if self.phaseDuration>=self.duration_thres and self.worseN>=self.worseN_thres:\n",
    "            # 复位 phaseDuration\n",
    "            self.phaseDuration = 0 \n",
    "            # 更新 phaseN\n",
    "            self.phaseN += 1\n",
    "            \n",
    "            # 设置lr的线性下降阶段\n",
    "            self.scheduler.start = self.scheduler.start\n",
    "            self.scheduler.end = self.scheduler.start / self.annealRate\n",
    "            self.scheduler.func = annealing_linear\n",
    "\n",
    "            self.scheduler.n_iter = self.annealIte\n",
    "            self.scheduler.n = 0\n",
    "\n",
    "            print(f'on end of epoch#{epoch}: start annealing from {self.scheduler.start} to {self.scheduler.end}')\n",
    "\n",
    "            # 如果不是最后一个phase\n",
    "            if self.phaseN<self.phaseMaxN:\n",
    "                # 使end稍降，n_iter稍增，防止下降结束后结束训练\n",
    "                self.scheduler.end -= (self.scheduler.start - self.scheduler.end)/self.annealIte\n",
    "                self.scheduler.n_iter += 1\n",
    "                # 设置 self.expectConstantLr=True，使下降阶段临结束时换为恒lr训练\n",
    "                self.expectConstantLr = True\n",
    "            # 如果是最后一个phase，则等待下降结束后自动结束训练，无需额外处理\n",
    "            \n",
    "    def on_batch_end(self, **kwargs):\n",
    "        # 如果正在等待下降阶段结束后开始恒lr训练，并且下降阶段已经到了马上结束的时候\n",
    "        if self.expectConstantLr and self.scheduler.n==(self.scheduler.n_iter-1):\n",
    "            self.expectConstantLr = False\n",
    "            self.scheduler.start = self.scheduler.start / self.annealRate\n",
    "            self.scheduler.end = self.scheduler.start\n",
    "            self.scheduler.func = annealing_no\n",
    "            \n",
    "            self.scheduler.n_iter = 1e99 # 将 n_iter 设置为一个非常大的数，防止该phase自动结束\n",
    "            self.scheduler.n = 0\n",
    "            \n",
    "            self._finetune_stop(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit_with_warmup_multiAnneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def fit_with_warmup_multiAnnealPlat(learn,\n",
    "                                    epoch_len:int=10,\n",
    "                                    num_epoch:int=100,\n",
    "                                    \n",
    "                                    lr_start:float=3e-4,\n",
    "                                    lr_constant:float=3e-3,\n",
    "                                    warmup_iter:int=10,\n",
    "                                    \n",
    "                                    monitor:str='valid',\n",
    "                                    worseN_thres:int=3,\n",
    "                                    annealRate:float=5,\n",
    "                                    duration_thres:int=5,\n",
    "                                    annealIte:int=200,\n",
    "                                    phaseMaxN:int=3,\n",
    "                                    finetune_stop=0,\n",
    "                                    callbacks=None)->None:\n",
    "    '''\n",
    "    训练开始时先warmup，然后以constant lr训练，valid loss到达平台后衰减lr继续constant lr训练，\n",
    "    如此直到设置的epoch上限，或者constant lr训练阶段数达到上限，结束训练。\n",
    "    参数：\n",
    "    -- learn：Learner对象\n",
    "    -- epoch_len：设置一个epoch包含的iteration数，（见CustomEpochLength的定义）。\n",
    "    -- num_epochs：训练epoch数上限\n",
    "    \n",
    "    -- lr_start：warmup起始lr\n",
    "    -- lr_constant：warmup结束lr，也是phase0的constant lr\n",
    "    -- warmup_iter：warmup持续iteration数\n",
    "    \n",
    "    -- worseN_thres：当有warseN_thres个epoch都没有出现更好的valid loss时，认为达到了平台\n",
    "    -- annealRate：valid loss到达平台后，将当前使用的lr衰减至1/annealRate\n",
    "    -- duration_thres：一个constant lr训练阶段至少持续duration_thres个epoch\n",
    "    -- annealIte：lr衰减至lr/annealRate经历的iteration数\n",
    "    -- phaseMaxN：至多phaseMaxN个训练阶段\n",
    "    -- finetune_stop：一个整数，在某个train phase刚开始，其lr稳定后，决定是否结束微调，变为全模型学习。若为0，则不起作用，即整个训练\n",
    "    过程维持开始的微调策略；若大于phaseMaxN，也不会起作用。\n",
    "    '''\n",
    "    # 先建一个基础scheduler\n",
    "    phase0 = TrainingPhase(warmup_iter).schedule_hp('lr',(lr_start,lr_constant),annealing_cos) # warmup\n",
    "    phase1 = TrainingPhase(len(learn.data.train_dl)*num_epoch-warmup_iter).schedule_hp('lr',lr_constant,annealing_no) # constant lr\n",
    "    base_sched = GeneralScheduler(learn, [phase0, phase1])\n",
    "    \n",
    "    \n",
    "    # 提取base_sched的constant lr部分，传入MultiAnneal_Scheduler，供其自适应调整\n",
    "    lr_sched = phase1.scheds['lr']\n",
    "    autoPhases = MultiAnneal_Scheduler(learn=learn,\n",
    "                                       base_lr_sched=lr_sched,\n",
    "                                       monitor=monitor,\n",
    "                                       worseN_thres=worseN_thres,\n",
    "                                       annealRate=annealRate,\n",
    "                                       duration_thres=duration_thres,\n",
    "                                       annealIte=annealIte,\n",
    "                                       phaseMaxN=phaseMaxN,\n",
    "                                       finetune_stop=finetune_stop)\n",
    "    \n",
    "    # 加入fit函数的callbacks中\n",
    "    callbacks = listify(callbacks)\n",
    "    callbacks.append(base_sched)\n",
    "    callbacks.append(autoPhases)\n",
    "    \n",
    "    # 设置一个epoch包含的iteration数\n",
    "    set_epochLen = CustomEpochLength(epoch_len=epoch_len)\n",
    "    callbacks.append(set_epochLen)\n",
    "    \n",
    "    learn.fit(num_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 设置device\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# databunch\n",
    "data = nb_databunch.get_databunch(data_root='./data/tiny_ds_20200331',bs=64,device=device,cache=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = nb_resnet_ssd.get_resnet18_ssd()\n",
    "model.load_state_dict(torch.load('./models/resnet18_ssd_init.pth'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learner\n",
    "learn = Learner(data,model)\n",
    "if device.type=='cuda':\n",
    "    learn.model = torch.nn.DataParallel(learn.model,device_ids=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 设置loss function\n",
    "gvs,_,_,avs,_,_ = nb_anchors_loss_metrics.get_ga()\n",
    "gaf = nb_anchors_loss_metrics.GridAnchor_Funcs(gvs,avs,device)\n",
    "learn.loss_func = partial(nb_anchors_loss_metrics.yolo_L, gaf=gaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 设置 optimizer\n",
    "learn.opt_func = partial(nb_optimizer.SU_Adam,betas=(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 添加metrics\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.clas_L,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.cent_L,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.hw_L,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.pConf_L,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.nConf_L,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.clas_acc,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.cent_d,gaf=gaf)]\n",
    "learn.metrics += [partial(nb_anchors_loss_metrics.hw_r,gaf=gaf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tensorboard callback\n",
    "# 指定tensorboard加载的总目录\n",
    "log_root = './tb_log/'\n",
    "# 先清空加载目录\n",
    "if os.path.exists(log_root): shutil.rmtree(log_root)\n",
    "os.mkdir(log_root)\n",
    "\n",
    "log_dir = f'{log_root}run#5'\n",
    "tbCb = nb_tensorboard_callback.TensorBoardCallback(\n",
    "                               learn=learn,\n",
    "                               log_dir=log_dir,\n",
    "                               plot_net=True,\n",
    "                               plot_loss=True,\n",
    "                               metric_plots=[],\n",
    "                               hyper_plots=['lr'],\n",
    "                               hist_plots=['res_blocks.0.0.conv1.weight',                                \n",
    "                                           'res_blocks.2.0.conv1.weight',\n",
    "                                           'res_blocks.4.0.conv1.weight'],\n",
    "                               hist_iters=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='9', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      77.78% [7/9 03:48<01:05]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>clas_L</th>\n",
       "      <th>cent_L</th>\n",
       "      <th>hw_L</th>\n",
       "      <th>pConf_L</th>\n",
       "      <th>nConf_L</th>\n",
       "      <th>clas_acc</th>\n",
       "      <th>cent_d</th>\n",
       "      <th>hw_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.902404</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.925025</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.881374</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.827936</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.486281</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.942138</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.435704</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [9/12 00:26<00:08 18.1872]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLERT: You are using CumtomEpochLength, please make sure that your training dataloader is using random sampler, or this may cause problem.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.00% [12/100 15:16<1:51:57]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>clas_L</th>\n",
       "      <th>cent_L</th>\n",
       "      <th>hw_L</th>\n",
       "      <th>pConf_L</th>\n",
       "      <th>nConf_L</th>\n",
       "      <th>clas_acc</th>\n",
       "      <th>cent_d</th>\n",
       "      <th>hw_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.401018</td>\n",
       "      <td>4.391027</td>\n",
       "      <td>2.026864</td>\n",
       "      <td>1.094021</td>\n",
       "      <td>0.372274</td>\n",
       "      <td>0.401282</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>1.204626</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.718062</td>\n",
       "      <td>4.198907</td>\n",
       "      <td>1.718222</td>\n",
       "      <td>1.199870</td>\n",
       "      <td>0.461305</td>\n",
       "      <td>0.372082</td>\n",
       "      <td>0.447428</td>\n",
       "      <td>0.354552</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>1.259477</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.151860</td>\n",
       "      <td>4.206512</td>\n",
       "      <td>1.819284</td>\n",
       "      <td>1.172115</td>\n",
       "      <td>0.414777</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.437243</td>\n",
       "      <td>0.341353</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>1.230669</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.857590</td>\n",
       "      <td>4.141801</td>\n",
       "      <td>1.823466</td>\n",
       "      <td>1.160300</td>\n",
       "      <td>0.364924</td>\n",
       "      <td>0.347988</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.338166</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>1.200265</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.653244</td>\n",
       "      <td>4.350423</td>\n",
       "      <td>1.951747</td>\n",
       "      <td>1.181375</td>\n",
       "      <td>0.427474</td>\n",
       "      <td>0.347231</td>\n",
       "      <td>0.442596</td>\n",
       "      <td>0.359559</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>1.238804</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.468748</td>\n",
       "      <td>67.948242</td>\n",
       "      <td>46.136398</td>\n",
       "      <td>10.159351</td>\n",
       "      <td>10.862513</td>\n",
       "      <td>0.359006</td>\n",
       "      <td>0.430968</td>\n",
       "      <td>0.350505</td>\n",
       "      <td>0.041811</td>\n",
       "      <td>inf</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.424093</td>\n",
       "      <td>30.914713</td>\n",
       "      <td>19.232460</td>\n",
       "      <td>6.779490</td>\n",
       "      <td>4.113703</td>\n",
       "      <td>0.360668</td>\n",
       "      <td>0.428393</td>\n",
       "      <td>0.355735</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>inf</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.369796</td>\n",
       "      <td>54.965199</td>\n",
       "      <td>40.565571</td>\n",
       "      <td>8.958403</td>\n",
       "      <td>4.653365</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>0.427153</td>\n",
       "      <td>0.359781</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>inf</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.393302</td>\n",
       "      <td>23.006367</td>\n",
       "      <td>15.626837</td>\n",
       "      <td>3.773280</td>\n",
       "      <td>2.782363</td>\n",
       "      <td>0.414052</td>\n",
       "      <td>0.409834</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>nan</td>\n",
       "      <td>inf</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.368105</td>\n",
       "      <td>5.853026</td>\n",
       "      <td>3.256611</td>\n",
       "      <td>1.266098</td>\n",
       "      <td>0.541549</td>\n",
       "      <td>0.354894</td>\n",
       "      <td>0.433874</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>1.311540</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.295436</td>\n",
       "      <td>5.641041</td>\n",
       "      <td>3.074096</td>\n",
       "      <td>1.357905</td>\n",
       "      <td>0.421894</td>\n",
       "      <td>0.355206</td>\n",
       "      <td>0.431941</td>\n",
       "      <td>0.416525</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>inf</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.377542</td>\n",
       "      <td>15.488827</td>\n",
       "      <td>11.390827</td>\n",
       "      <td>1.983534</td>\n",
       "      <td>1.238569</td>\n",
       "      <td>0.492465</td>\n",
       "      <td>0.383433</td>\n",
       "      <td>0.413871</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>inf</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [4/12 00:17<00:34 4.3839]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d9c75d18b75a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0mannealIte\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                 \u001b[0mphaseMaxN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                 callbacks=[tbCb])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-39ac57c2db11>\u001b[0m in \u001b[0;36mfit_with_warmup_multiAnnealPlat\u001b[0;34m(learn, epoch_len, num_epoch, lr_start, lr_constant, warmup_iter, monitor, worseN_thres, annealRate, duration_thres, annealIte, phaseMaxN, callbacks)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_epochLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai_tb/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_tb/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_tb/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_tb/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai_tb/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code_space/detect_symbol/exp/nb_optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;31m# state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;31m# debias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code_space/detect_symbol/exp/nb_optimizer.py\u001b[0m in \u001b[0;36m_update_state\u001b[0;34m(self, group, state, grad)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_unit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_unit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_unit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit\n",
    "fit_with_warmup_multiAnnealPlat(learn,\n",
    "                                epoch_len=10,\n",
    "                                num_epoch=100,\n",
    "\n",
    "                                lr_start=3e-3,\n",
    "                                lr_constant=3e-2,\n",
    "                                warmup_iter=10,\n",
    "                                \n",
    "                                monitor='train_smooth',\n",
    "                                worseN_thres=20,\n",
    "                                annealRate=5,\n",
    "                                duration_thres=20,\n",
    "                                annealIte=10,\n",
    "                                phaseMaxN=3,\n",
    "                                callbacks=[tbCb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted scheduling_train.ipynb to exp/nb_scheduling_train.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py --fname 'scheduling_train.ipynb' --outputDir './exp/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
