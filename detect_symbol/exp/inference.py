
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/inference.ipynb

#================================================
from ..exp import interpretation


#================================================
from pathlib import Path


#================================================
import torch


#================================================
from torch import tensor


#================================================
import re
import os


#================================================
from matplotlib import pyplot as plt


#================================================
def get_model_size(model):
    '''
    统计并打印模型的参数个数和占内存大小。
    ========参数：
    --model：模型对象
    ========返回值：
    --cnt：模型包含的参数个数
    --msize: 模型参数占用的内存空间，单位byte
    '''
    cnt = 0
    msize = 0

    for v in model.parameters():
        cnt += v.data.nelement()
        msize += v.data.nelement()*v.data.element_size()
    print('{:.2f}M个参数，{:.2f}Mbyte'.format(cnt/1024/1024,msize/1024/1024))

    return cnt,msize


#================================================
class Normalizer():
    '''
    对图像做normalization：
    result = ((image/scale)-mean)/std
    '''
    def __init__(self,mean,std,device,scale=255):
        self.mean = mean.to(device)
        self.std = std.to(device)

    def __call__(self,x):
        res = x/255
        res = (res-self.mean)/self.std
        return res


#================================================
tail_pat = re.compile(r'^.*\.(\w+)$')
def img_names(fold_path):
    '''
    获取目录fold_path内的所有.png和.jpg格式的图片文件
    ========参数：
    --fold_path：目录路径
    ========返回值：
    --一个list，每个元素是一个图片文件的绝对路径
    '''
    res = []

    fnames = list(map(lambda fn: fold_path+fn, os.listdir(fold_path)))
    for fname in fnames:
        tail = tail_pat.findall(fname)
        if len(tail)==1 and (tail[0] in ['png', 'jpg']):
            res += [fname]

    return res


#================================================
def pth2pkl(learner,pth_file,pkl_file):
    '''
    将pth格式的checkpoint文件导出为pkl格式的二进制文件
    ----参数----
    learner：一个fastai的Learner对象
    pth_file：checkpoint文件路径
    pkl_file：导出目标路径
    ----返回值----
    无返回值
    '''
    with open(pth_file,'rb') as f:
        learner.load(f,device='cpu',with_opt=False)

    # 把模型状态导出为pkl
    with open(pkl_file,'wb') as f:
        learner.export(f)


#================================================
class Predictor():
    '''
    从.pkl文件中的信息构造normalizer和model，并利用二者以及postProcessor，构造出一个
    input => [normalizer->model->postProcessor] => prediction 的整体处理流程
    '''
    def __init__(self, pkl_file, device, device_ids=[0], normScale=255, postProcessor=None):
        '''
        ----参数----
        pkl_file：pkl文件路径
        device：整个处理流程在什么设备上执行
        device_ids：如果device是GPU，这里指定使用多核序号
        normScale：构造normalizer要用的参数，见Normalizer类
        postProcessor：callable，对model的输出做处理，得到最终的预测结果
        '''
        self.device = device

        with open(pkl_file,'rb') as f:
            state = torch.load(f)

        self.normalizer = self.make_normalizer(state, normScale)
        self.model = self.make_model(state, device_ids)
        self.postProcessor = postProcessor
        self.classes = state['data']['y_proc'][0].classes[1:]

    def make_normalizer(self, state, normScale):
        mean = state['data']['normalize']['mean']
        std = state['data']['normalize']['std']
        return Normalizer(mean[None,:,None,None],
                           std[None,:,None,None],
                           self.device, normScale)

    def make_model(self,state,device_ids):
        model = state['model']
        # 如果model是DataParallel，把里边的模型拿出来
        if hasattr(model, "module"):
            model = model.module

        # 把模型放到device上，如果使用GPU，则设置使用哪几个GPU
        model.to(self.device)
        if self.device.type=='cuda':
            model = torch.nn.DataParallel(model,device_ids=device_ids)

        # 把模型设置为eval模式，防止其batchnorm状态发生变化
        model.eval()
        return model

    def __call__(self, imgs):
        '''
        ----参数----
        --imgs：输入一个batch的图像数据，形状为 [bs,3,h,w]
        '''
        res = imgs.float().to(self.device)
        res = self.normalizer(res)
        res = self.model(res)
        if self.postProcessor is not None:
            res = self.postProcessor(res)
        return res


#================================================
def savePred_asFig(batch_x,
                   batch_boxs,
                   batch_cats,
                   batch_scores,
                   classes,
                   root_path,
                   suffix='.jpg',
                   startIdx=0):
    '''
    输入原图，nms处理后的模型预测，绘制这些预测并保存为图片。以batch为单位处理。
    ------------------------------
    ====参数：
    -- batch_x：一个batch的图片，像素值应在[0,1]或[0,255]范围内，图片 shape 应为 height * width * channel
    -- batch_boxs：目标框，每个框表示为（左上角x，左上角y，右下角x，右下角y）
    -- batch_cats：类别，每个类别以整数表示，该整数作为classes的索引
    -- batch_scores：目标得分，可以是confidence，也可以是f1得分(=conf*prb/(conf+prb))，你传入什么就打印什么
    -- classes：一个list，元素为字符串，是各类别的名称，其顺序应与batch_cats对应
    -- root_path：保存图片的文件夹路径
    -- suffix：图片文件名后缀，.jpg或.png，默认.jpg
    -- startIdx：例如设置startIdx=100，则图片名为100.jpg，101.jpg，...（这里以后缀为.jpg为例），该功能是为了防止将已有图片覆盖
    '''
    bs = len(batch_cats)

    for i in range(bs):
        fig,ax = plt.subplots(1,1)
        ax.axis('off')

        x = batch_x[i]
        x = x.permute(1,2,0)
        ax.imshow(x)

        h,w = x.shape[:2]
        img_s = tensor([h,w,h,w]).to(batch_boxs[0].device)

        boxs = batch_boxs[i]
        cats = batch_cats[i]
        scores = batch_scores[i]

        for j in range(len(cats)):
            box = boxs[j]*img_s
            interpretation.draw_rect(ax,box,lw=1)

            cat = cats[j]
            clas = classes[cat][:3]
            score = scores[j]
            info = '{}_{:.2f}'.format(clas,score*100)
            interpretation.draw_text(ax,box[[3,0]],info,sz=8)

        fig.savefig(Path(root_path)/(str(startIdx+i)+suffix))
