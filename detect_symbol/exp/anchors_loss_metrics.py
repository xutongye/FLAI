
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/anchors_loss_metrics.ipynb

#================================================
import torch


#================================================
from torch.nn import functional as F


#================================================
from torch import tensor


#================================================
from IPython.core import debugger as idb


#================================================
import numpy as np


#================================================
import math


#================================================
def get_grids_anchors(fig_hw, grids, anchors):
    '''
    生成所有grid和anchor的位置和形状信息。
    参数：
        fig_hw：图片尺寸，其形式为：(h，w)，例如（512，512）;
        grids：各层特征图的尺寸，其形式为：[(h0,w0),(h1,w1),...]
        anchors：各层特征图上使用的anchor的尺寸，每层特征图可以有多个anchor，且各层的anchor数不必相等。
            其形式为：[[(h00,w00),(h01,w01),...], [(h10,w10),(h11,w11),...], ...]

    返回值：
        gvs: 各grid的左上和右下角的坐标
        ghs：各grid的高度
        gws：各grid的宽度
        avs：各anchor的左上和右下角的坐标
        ahs：各anchor的高度
        aws：各anchor的宽度
        注意：以上坐标、高度、宽度都是以图片尺寸(fig_hw)为单位参照的
    '''
    fig_h,fig_w = fig_hw
    anchors = [[(ah/fig_h, aw/fig_w) for (ah,aw) in ancs] for ancs in anchors]
    gridCnrs_ancCnrs = tensor([[x/gx, y/gy, (x+1)/gx, (y+1)/gy,
                                -ax/2, -ay/2, ax/2, ay/2]
                                for (gx,gy),ancs in zip(grids,anchors)
                                for y in range(gy)
                                for x in range(gx)
                                for ax,ay in ancs])

    # grid corners, (use v to represent corners)
    gvs = gridCnrs_ancCnrs[:,:4]

    # grid heights and widths
    ghs = gvs[:,2] - gvs[:,0]
    gws = gvs[:,3] - gvs[:,1]

    # anchor corners
    avs = gridCnrs_ancCnrs[:,4:]

    # anchor heights and widthds
    ahs = avs[:,2] - avs[:,0]
    aws = avs[:,3] - avs[:,1]

    return gvs,ghs,gws,avs,ahs,aws


#================================================
# 此函数仅在detect_symbol项目下使用
def get_ga433():
    return get_grids_anchors(fig_hw = (784,784),
                              grids = [(49,49),(25,25),(13,13)],
                              anchors = [[(22,17),(22,37),(43,17),(43,37)],
                                         [(43,77),(83,37),(83,77)],
                                         [(83,162),(162,77),(162,162)]])


#================================================
# 此函数仅在detect_symbol项目下使用
def get_ga444():
    return get_grids_anchors(fig_hw = (784,784),
                              grids = [(49,49),(25,25),(13,13)],
                              anchors = [[(22,17),(22,37),(43,17),(43,37)],
                                         [(43,37),(43,77),(83,37),(83,77)],
                                         [(83,77),(83,162),(162,77),(162,162)]])


#================================================
# 此函数仅在detect_symbol项目下使用
def get_ga666():
    return get_grids_anchors(fig_hw = (776,776),
                              grids = [(97,97),(49,49),(25,25)],
                              anchors = [[( 34, 3),( 34,10),( 34, 30),(13, 30),( 5, 30),(13,10)],
                                         [( 92,10),( 92,30),( 92, 87),(35, 87),(13, 87),(34,30)],
                                         [(244,30),(244,87),(244,254),(92,254),(35,254),(92,87)]])


#================================================
def t2b(t,idx,eps=1):
    cx,cy = gvs[idx,0],gvs[idx,1]
    gh,gw = ghs[idx],gws[idx]
    ph,pw = ahs[idx],aws[idx]

    sig_tx = torch.sigmoid(t[:,0])
    sig_ty = torch.sigmoid(t[:,1])
    exp_th = torch.exp(t[:,2])
    exp_tw = torch.exp(t[:,3])

    hatsig_tx = (1+eps)*(sig_tx-0.5) + 0.5
    hatsig_ty = (1+eps)*(sig_ty-0.5) + 0.5

    bx = hatsig_tx*gw + cx # x of center of box
    by = hatsig_ty*gh + cy # y of center of box

    bh = ph * exp_th    # height of box
    bw = pw * exp_tw    # width of box

    tl_x = bx - bh/2 # x of top-left corner of box
    tl_y = by - bw/2 # y of top-left corner of box
    br_x = bx + bh/2 # x of bottom-right corner of box
    br_y = by + bw/2 # y of bottom-right corner of box

    return torch.stack([tl_x, tl_y, br_x, br_y]).t()


#================================================
def b2t(b,idx,eps=1):
    cx,cy = gvs[idx,0],gvs[idx,1]
    gh,gw = ghs[idx],gws[idx]
    ph,pw = ahs[idx],aws[idx]

    bx = (b[:,0] + b[:,2])/2 # x of center of box
    by = (b[:,1] + b[:,3])/2 # y of center of box
    bh = b[:,2] - b[:,0]     # height of box
    bw = b[:,3] - b[:,1]     # width of box

    hatsig_tx = (bx - cx)/gh
    hatsig_ty = (by - cy)/gw
    exp_th = bh / ph
    exp_tw = bw / pw

    sig_tx = (hatsig_tx+0.5*eps)/(1+eps)
    sig_ty = (hatsig_ty+0.5*eps)/(1+eps)

    tx = torch.log(sig_tx/(1-sig_tx))
    ty = torch.log(sig_ty/(1-sig_ty))
    th = torch.log(exp_th)
    tw = torch.log(exp_tw)

    return torch.stack([tx, ty, th, tw]).t()


#================================================
def bbox2chw(b):
    '''
    将bbox的（左上x，左上y，右下x，右下y）表示变为（中心x，中心y，高，宽）表示
    '''
    cx = b[...,[0,2]].mean(-1)[...,None]
    cy = b[...,[1,3]].mean(-1)[...,None]

    h = (b[...,2]-b[:,0])[...,None]
    w = (b[...,3]-b[:,1])[...,None]

    return torch.cat([cx,cy,h,w],dim=-1)


#================================================
def get_y(bboxs):
    bboxs = bboxs.view(-1,4)
    keep = bboxs.abs().sum(-1).nonzero()[:,0]
    return keep


#================================================
def intersect(box_a, box_b):
    max_xy = torch.min(box_a[..., 2:], box_b[..., 2:])
    min_xy = torch.max(box_a[..., :2], box_b[..., :2])
    inter = torch.clamp((max_xy - min_xy), min=0)
    return inter[..., 0] * inter[..., 1]

def box_sz(b): return ((b[..., 2]-b[..., 0]) * (b[..., 3]-b[..., 1]))

def iou(box_a, box_b):
    inter = intersect(box_a, box_b)
    union = box_sz(box_a) + box_sz(box_b) - inter
    return inter / union


#================================================
def get_scores_hits(gt_bboxs):
    # ground truch bbox center x,y
    gt_cx = gt_bboxs[:,[0,2]].mean(-1)
    gt_cy = gt_bboxs[:,[1,3]].mean(-1)

    # find the center where the anchors will be shifted at.
    anc_cx = (gt_cx[:,None]<gvs[:,0]).float() * (gvs[:,0]-gt_cx[:,None]) + \
             (gt_cx[:,None]>gvs[:,2]).float() * (gvs[:,2]-gt_cx[:,None]) + \
              gt_cx[:,None];
    anc_cy = (gt_cy[:,None]<gvs[:,1]).float() * (gvs[:,1]-gt_cy[:,None]) + \
             (gt_cy[:,None]>gvs[:,3]).float() * (gvs[:,3]-gt_cy[:,None]) + \
              gt_cy[:,None];

    # shift anchors at center (anc_cx, anc_cy)
    # fxdAncCnrs: fixed anchor corners
    fxdAncVs = avs + torch.cat([anc_cx[...,None], anc_cy[...,None]],dim=-1).repeat(1,1,2)

    # 匹配度得分
    scores = iou(gt_bboxs[:,None,:], fxdAncVs)

    # 判断目标bbox的中心落在哪个cell内
    hits = ((gt_cx[:,None] >= gvs[:,0][None]) &
            (gt_cx[:,None] <  gvs[:,2][None]) &
            (gt_cy[:,None] >= gvs[:,1][None]) &
            (gt_cy[:,None] <  gvs[:,3][None]))

    return scores,hits


#================================================
def idx_fromScoresHits(scores,hits):
    idx = (scores*hits.float()).max(1)[1]
    return idx


#================================================
def get_clasWeights(clas_cnts=[], max_imblance=5):
    if max_imblance<=1:
        max_imblance = 1.01

    clas_cnts = np.array(clas_cnts)
    N = len(clas_cnts)
    minCnt = min(clas_cnts)
    maxCnt = max(clas_cnts)

    eta = (maxCnt-minCnt*max_imblance)/(max_imblance-1)
    eta = max(eta,0)

    expect_cnts = clas_cnts + eta
    weights = expect_cnts/clas_cnts
    weights = weights * N / weights.sum()

    return weights


#================================================
def clas_L(pred_batch, *gt_batch, lambda_clas=1, clas_weights=None, gaf):
    loss = 0
    cnt = 0
    for pred_clas,gt_bboxs,gt_clas in zip(pred_batch[2], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        pred_clas = pred_clas[idx]

        loss += F.cross_entropy(pred_clas, gt_clas, weight=clas_weights, reduction='sum')
        cnt += gt_clas.shape[0]

    return lambda_clas*loss/cnt


#================================================
def cent_L(pred_batch, *gt_batch, lambda_cent=1, clas_weights=None, gaf):
    loss = 0
    cnt = 0
    for pred_txy,gt_bboxs,gt_clas in zip(pred_batch[0], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1

        if clas_weights is not None: ws = clas_weights[gt_clas]
        else: ws = None

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)
        pred_txy = pred_txy[idx]

        if ws is not None:
            tmp = ((gt_t[...,:2]-pred_txy)*ws[...,None]).abs().sum()
        else:
            tmp = (gt_t[...,:2]-pred_txy).abs().sum()

        loss += tmp
        cnt += len(idx)

    return lambda_cent*loss/cnt


#================================================
def pConf_L(pred_batch, *gt_batch, lambda_pconf=1, clas_weights=None, gaf):
    loss = 0
    cnt = 0
    for pred_conf,gt_bboxs,gt_clas in zip(pred_batch[1], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1

        if clas_weights is not None: ws = clas_weights[gt_clas]
        else: ws = None

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        conf_pos = pred_conf[idx]
#         conf_pos = torch.sigmoid(conf_pos)
#         tmp = (1-conf_pos).abs().sum()
        if ws is not None:
            tmp = F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),weight=ws[...,None],reduction='sum')
        else:
            tmp = F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),reduction='sum')


        loss += tmp
        cnt += len(idx)

    return lambda_pconf*loss/cnt


#================================================
def nConf_L(pred_batch, *gt_batch, gaf, conf_th=0.5, lambda_nconf=1):
    loss = 0
    cnt = 0
    for pred_conf,gt_bboxs,_ in zip(pred_batch[1], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_bboxs = (gt_bboxs + 1) / 2

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        scores[range(0,len(idx)),idx] = conf_th + 1 # 强制责任anchor的得分好于threshold
        tmp = scores>conf_th # 判断各得分是否好于threshold
        tmp = tmp.max(dim=0)[0] # 各anchor是否有任意一个好于threshold的得分
        neg_idx = torch.where(tmp==0)[0] # 如果没有，该anchor是negative anchor

        conf_neg = pred_conf[neg_idx]
#         conf_neg = torch.sigmoid(conf_neg)
#         loss += conf_neg.abs().sum()
        tmp = F.binary_cross_entropy_with_logits(conf_neg,torch.zeros_like(conf_neg),reduction='sum')
        loss += tmp
        cnt += len(neg_idx)

    return lambda_nconf*loss/cnt


#================================================
def hw_L(pred_batch, *gt_batch, gaf, lambda_hw=1, clas_weights=None):
    loss = 0
    cnt = 0
    for pred_thw,gt_bboxs,gt_clas in zip(pred_batch[3], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1

        if clas_weights is not None: ws = clas_weights[gt_clas]
        else: ws = None

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)
        pred_thw = pred_thw[idx]

        if ws is not None:
            tmp = ((gt_t[...,2:]-pred_thw)*ws[...,None]).abs().sum()
        else:
            tmp = (gt_t[...,2:]-pred_thw).abs().sum()

        loss += tmp
        cnt += len(idx)

    return lambda_hw*loss/cnt


#================================================
def yolo_L(pred_batch, *gt_batch, conf_th=0.5,
           lambda_cent=1, lambda_pconf=1, lambda_nconf=1, lambda_clas=1, lambda_hw=1, clas_weights=None, gaf):
    '''
    clas_weights:
    为了解决数据集的imbalance问题，一种方法是在dataloader中使用WeightedRandomSampler，但是这种方法不适用于目标检测问题。
    因为，（1）目标检测的label不是一个简单的数值（2）目标检测问题的一张图片可能包括不同类别的多个目标。
    所以为了解决目标检测问题中的imbalance问题，我们的方法是在损失函数中使用权重。
    为各类别分配权重，各目标对应的损失乘以该目标所属类别的权重。
    默认为None，即不使用权重。
    若设置非None，则clas_weights应该是一个一维tensor，其长度等于数据集的类别数。
    若设置为全1，则相当于不使用权重。
    合理的设置应保证所有元素之和等于数据集的类别数，否则相当于对损失函数的整体做了缩放。
    '''
    clas_loss = 0
    cent_loss = 0
    pconf_loss = 0
    nconf_loss = 0
    hw_loss = 0
    pos_cnt = 0
    neg_cnt = 0

    for pred_txy,pred_conf,pred_clas,pred_thw,gt_bboxs,gt_clas in zip(*pred_batch, *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1

        if clas_weights is not None: ws = clas_weights[gt_clas]
        else: ws = None

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        # classification loss
        pred_clas = pred_clas[idx]
        clas_loss += F.cross_entropy(pred_clas, gt_clas, weight=clas_weights, reduction='sum')

        # bbox center loss
        gt_t = gaf.b2t(gt_bboxs,idx,eps=1)
        pred_txy = pred_txy[idx]
        if ws is not None:
            cent_loss += ((gt_t[...,:2]-pred_txy)*ws[...,None]).abs().sum()
        else:
            cent_loss += (gt_t[...,:2]-pred_txy).abs().sum()

        # bbox height and width loss
        pred_thw = pred_thw[idx]
        if ws is not None:
            hw_loss += ((gt_t[...,2:]-pred_thw)*ws[...,None]).abs().sum()
        else:
            hw_loss += (gt_t[...,2:]-pred_thw).abs().sum()

        # positive confidence loss
        conf_pos = pred_conf[idx]
        if ws is not None:
            pconf_loss += F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),weight=ws[...,None],reduction='sum')
        else:
            pconf_loss += F.binary_cross_entropy_with_logits(conf_pos,torch.ones_like(conf_pos),reduction='sum')

        # negative conficence loss
        scores[range(0,len(idx)),idx] = conf_th + 1 # 强制责任anchor的得分好于threshold
        tmp = scores>conf_th # 判断各得分是否好于threshold
        tmp = tmp.max(dim=0)[0] # 各anchor是否有任意一个好于threshold的得分
        neg_idx = torch.where(tmp==0)[0] # 如果没有，该anchor是negative anchor
        conf_neg = pred_conf[neg_idx]
        nconf_loss += F.binary_cross_entropy_with_logits(conf_neg,torch.zeros_like(conf_neg),reduction='sum')

        pos_cnt += len(idx)
        neg_cnt += len(neg_idx)

    clas_loss  = lambda_clas  * clas_loss  /pos_cnt
    cent_loss  = lambda_cent  * cent_loss  /pos_cnt
    pconf_loss = lambda_pconf * pconf_loss /pos_cnt
    nconf_loss = lambda_nconf * nconf_loss /neg_cnt
    hw_loss    = lambda_hw    * hw_loss   /pos_cnt

    return clas_loss + cent_loss + pconf_loss + nconf_loss + hw_loss


#================================================
class GridAnchor_Funcs():
    def __init__(self,gvs,avs,device):
        '''
        基于grid和anchor的函数，这些函数都需要访问grid和anchor数据，因此构造一个类，把grid和anchor数据跟这些函数绑在一起。
        参数：
        -- gvs: grid corner coordinates, tensor([[min_x0,min_y0,max_x0,max_y0],[min_x1,min_y1,max_x1,max_y1],...])的形式
        -- avs: anchor corner coordinates, tensor([[min_x0,min_y0,max_x0,max_y0],[min_x1,min_y1,max_x1,max_y1],...])的形式
        -- device: a torch.device object
        '''
        self.gvs = gvs.to(device)
        self.avs = avs.to(device)

        self.ghs = self.gvs[...,2] - self.gvs[...,0] # gh: grid height
        self.gws = self.gvs[...,3] - self.gvs[...,1] # gw: grid width
        self.ahs = self.avs[...,2] - self.avs[...,0] # ah: anchor height
        self.aws = self.avs[...,3] - self.avs[...,1] # aw: anchor width

    def t2b(self,t,idx,eps=1):
        cx,cy = self.gvs[idx,0],self.gvs[idx,1]
        gh,gw = self.ghs[idx],self.gws[idx]
        ph,pw = self.ahs[idx],self.aws[idx]

        sig_tx = torch.sigmoid(t[...,0])
        sig_ty = torch.sigmoid(t[...,1])
        exp_th = torch.exp(t[...,2])
        exp_tw = torch.exp(t[...,3])

        hatsig_tx = (1+eps)*(sig_tx-0.5) + 0.5
        hatsig_ty = (1+eps)*(sig_ty-0.5) + 0.5

        bx = hatsig_tx*gw + cx # x of center of box
        by = hatsig_ty*gh + cy # y of center of box

        bh = ph * exp_th    # height of box
        bw = pw * exp_tw    # width of box

        tl_x = bx - bh/2 # x of top-left corner of box
        tl_y = by - bw/2 # y of top-left corner of box
        br_x = bx + bh/2 # x of bottom-right corner of box
        br_y = by + bw/2 # y of bottom-right corner of box

        res = torch.stack([tl_x, tl_y, br_x, br_y],dim=0)
        res = res.permute(list(range(len(res.shape)))[1:]+[0])
        return res

    def b2t(self, b,idx,eps=1):
        cx,cy = self.gvs[idx,0],self.gvs[idx,1]
        gh,gw = self.ghs[idx],self.gws[idx]
        ph,pw = self.ahs[idx],self.aws[idx]

        bx = (b[:,0] + b[:,2])/2 # x of center of box
        by = (b[:,1] + b[:,3])/2 # y of center of box
        bh = b[:,2] - b[:,0]     # height of box
        bw = b[:,3] - b[:,1]     # width of box

        hatsig_tx = (bx - cx)/gh
        hatsig_ty = (by - cy)/gw
        exp_th = bh / ph
        exp_tw = bw / pw

        sig_tx = (hatsig_tx+0.5*eps)/(1+eps)
        sig_ty = (hatsig_ty+0.5*eps)/(1+eps)

        tx = torch.log(sig_tx/(1-sig_tx))
        ty = torch.log(sig_ty/(1-sig_ty))
        th = torch.log(exp_th)
        tw = torch.log(exp_tw)

        return torch.stack([tx, ty, th, tw]).t()

    def get_scores_hits(self, gt_bboxs):
        # ground truch bbox center x,y
        gt_cx = gt_bboxs[:,[0,2]].mean(-1)
        gt_cy = gt_bboxs[:,[1,3]].mean(-1)

        # find the center where the anchors will be shifted at.
        anc_cx = (gt_cx[:,None]<self.gvs[:,0]).float() * (self.gvs[:,0]-gt_cx[:,None]) + \
                 (gt_cx[:,None]>self.gvs[:,2]).float() * (self.gvs[:,2]-gt_cx[:,None]) + \
                  gt_cx[:,None];
        anc_cy = (gt_cy[:,None]<self.gvs[:,1]).float() * (self.gvs[:,1]-gt_cy[:,None]) + \
                 (gt_cy[:,None]>self.gvs[:,3]).float() * (self.gvs[:,3]-gt_cy[:,None]) + \
                  gt_cy[:,None];

        # shift anchors at center (anc_cx, anc_cy)
        # fxdAncCnrs: fixed anchor corners
        fxdAncVs = self.avs + torch.cat([anc_cx[...,None], anc_cy[...,None]],dim=-1).repeat(1,1,2)

        # 匹配度得分
        scores = iou(gt_bboxs[:,None,:], fxdAncVs)

        # 判断目标bbox的中心落在哪个cell内
        hits = ((gt_cx[:,None] >= self.gvs[:,0][None]) &
                (gt_cx[:,None] <  self.gvs[:,2][None]) &
                (gt_cy[:,None] >= self.gvs[:,1][None]) &
                (gt_cy[:,None] <  self.gvs[:,3][None]))

        return scores,hits


#================================================
def clas_acc(pred_batch, *gt_batch, gaf):
    posCnt = tensor(0.)
    totCnt = tensor(0.)
    for pred_clas,gt_bboxs,gt_clas in zip(pred_batch[2], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        gt_bboxs = gt_bboxs[keep]
        gt_clas = gt_clas[keep]

        gt_bboxs = (gt_bboxs + 1) / 2
        gt_clas = gt_clas - 1 # the databunch add a 'background' class to classes[0], but we don't want that,so gt_clas-1

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        pred_clas = pred_clas[idx]
        pred_clas = pred_clas.max(1)[1]

        posCnt += (pred_clas==gt_clas).sum().item()
        totCnt += gt_clas.shape[0]

    return posCnt/totCnt


#================================================
def cent_d(pred_batch, *gt_batch, gaf):
    dif = tensor(0.)
    cnt = tensor(0.)
    for pred_txy,pred_thw,gt_bboxs,_ in zip(pred_batch[0],pred_batch[3], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        pred_t = torch.cat([pred_txy,pred_thw],dim=1)

        gt_bboxs = gt_bboxs[keep]
        gt_bboxs = (gt_bboxs + 1) / 2

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        pred_t = pred_t[idx]
        pred_c = bbox2chw(gaf.t2b(pred_t,idx))[...,:2]
        gt_c = bbox2chw(gt_bboxs)[...,:2]

        tmp = (gt_c - pred_c).abs().sum()
        dif += tmp
        cnt += len(idx)

    return dif/cnt/2


#================================================
def hw_r(pred_batch, *gt_batch, gaf):
    logR = tensor(0.)
    cnt = tensor(0.)
    for pred_txy,pred_thw,gt_bboxs,_ in zip(pred_batch[0],pred_batch[3], *gt_batch):
        keep = get_y(gt_bboxs)
        if keep.numel()==0: continue

        pred_t = torch.cat([pred_txy,pred_thw],dim=1)

        gt_bboxs = gt_bboxs[keep]
        gt_bboxs = (gt_bboxs + 1) / 2

        scores,hits = gaf.get_scores_hits(gt_bboxs)
        idx = idx_fromScoresHits(scores,hits)

        pred_t = pred_t[idx]
        pred_hw = bbox2chw(gaf.t2b(pred_t,idx))[...,2:]
        gt_hw = bbox2chw(gt_bboxs)[...,2:]

        tmp = (pred_hw/gt_hw).log().abs().sum()
        logR += tmp
        cnt += len(idx)

    return (logR/(cnt*2)).exp() # *2是因为每个bbox有h和w，h和w的贡献在logR中被加在一起了，而cnt仅是对bbox的计数
